# OpenAI API-compatible endpoint
# Examples:
# - GitHub Models: https://models.inference.ai.azure.com
# - Groq: https://api.groq.com/openai/v1
# - Ollama: http://localhost:11434/v1
LLM_BASE_URL=https://models.inference.ai.azure.com

# API key for the provider (not needed for Ollama)
# Leave empty or omit for Ollama, it defaults to "ollama"
API_KEY=your_api_key_here

# Model name (check your provider's available models)
LLM_MODEL=gpt-4o